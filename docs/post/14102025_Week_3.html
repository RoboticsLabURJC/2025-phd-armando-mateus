<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Armando Mateus Week 3</title>
  <link rel="stylesheet" href="../style.css">
</head>
<body>
  <header class="site-header">
    <div class="header-container">
      <img src="../images/logo.png" alt="Logo" class="logo">
      <div class="header-text">
        <h1>Robotics Lab URJC</h1>
        <p>Programming Robot Intelligence</p>
      </div>
    </div>
    <nav>
      <a href="../index.html">Inicio</a>
    </nav>
  </header>

  <main class="container">
    <article class="post">
      <h2>Week 3 - Shifting Focus to MobileNet Architecture</h2>
      <p class="date">October 14, 2025</p>
      
      <p><strong>New Research Direction: MobileNet Architecture</strong></p>
      
      <p>After achieving promising technical results with CARLA Simulator, ROS2, and the CARLA API, I'm now tackling a more advanced challenge. My research focus has shifted to studying MobileNet architectures, beginning with comprehensive literature review and initial implementation setup.</p>
      
      <p>Currently, I'm evaluating optimal hardware configuration requirements, including GPU capabilities and RAM specifications, along with integrating a Logitech G920 driving wheel. While numerous commercial options are available, key considerations involve determining the actual requirements for future model training in CARLA. The inclusion of features such as three versus two pedals, shifters, and paddle shifters may not be essential but could potentially provide additional training data dimensions.</p>
      
      <p>Although creating a customized setup for end-to-end driving training is feasible, I'm building upon the dataset developed by William Aristizabal and Juan Manuel Calderon, described in [1], which provides an exploratory framework for end-to-end training methodologies.</p>
      
      <p>I have completed the foundational study of Sergio Paniego's research through detailed analysis of references [2], [3], and [4], which provide valuable insights into deep learning approaches for autonomous driving systems.</p>
      
      <div class="references">
        <p><strong>References:</strong></p>
        <p>[1] W. Aristizabal, S. Amaya, and J. M. Calderon, "End-to-End Deep Learning Approach for Comprehensive Autonomous Driving in Simulated Environments," in <em>SoutheastCon 2025</em>, pp. 983-988, Mar. 2025.</p>
        
        <p>[2] S. Paniego, V. Sharma, and J. M. Cañas, "Open source assessment of deep learning visual object detection," <em>Sensors</em>, vol. 22, no. 12, p. 4575, 2022.</p>
        
        <p>[3] S. Paniego, R. Calvo-Palomino, and J. Cañas, "Enhancing end-to-end control in autonomous driving through kinematic-infused and visual memory imitation learning," <em>Neurocomputing</em>, vol. 600, p. 128161, 2024.</p>
        
        <p>[4] S. Paniego, E. Shinohara, and J. Canas, "Autonomous driving in traffic with end-to-end vision-based deep learning," <em>Neurocomputing</em>, vol. 594, p. 127874, 2024.</p>
      </div>
    </article>
  </main>

  <footer class="site-footer">
    <p>© 2025 - Academic Blog by Armando Mateus</p>
  </footer>
</body>
</html>
